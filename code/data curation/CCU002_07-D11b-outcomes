# Databricks notebook source
# MAGIC %md # CCU002_07-D11b-outcomes
# MAGIC
# MAGIC **Description** This notebook creates the outcomes table for vaccination.
# MAGIC
# MAGIC **Authors** Alexia Sampri
# MAGIC
# MAGIC **Reviewers** Wen Shi
# MAGIC
# MAGIC **Acknowledgements** Based on previous work by Tom Bolton (John Nolan, Elena Raffetti) for CCU018_01 and the earlier CCU002 sub-projects.
# MAGIC
# MAGIC **Notes**

# COMMAND ----------

spark.sql('CLEAR CACHE')

# COMMAND ----------

# DBTITLE 1,Libraries
import pyspark.sql.functions as f
import pyspark.sql.types as t
from pyspark.sql import Window

from functools import reduce

import databricks.koalas as ks
import pandas as pd
import numpy as np

#import the pyspaprk module
from pyspark.sql.functions import col,lit,when

import re
import io
import datetime

import matplotlib
import matplotlib.pyplot as plt
from matplotlib import dates as mdates
import seaborn as sns

print("Matplotlib version: ", matplotlib.__version__)
print("Seaborn version: ", sns.__version__)
_datetimenow = datetime.datetime.now() # .strftime("%Y%m%d")
print(f"_datetimenow:  {_datetimenow}")

# COMMAND ----------

# DBTITLE 1,Functions
# MAGIC %run "../shds/common/functions"

# COMMAND ----------

# MAGIC %md # 0 Parameters

# COMMAND ----------

# MAGIC %run "./CCU002_07-D01-parameters"

# COMMAND ----------

# MAGIC %md # 1 Data

# COMMAND ----------

codelist     = spark.table(path_out_codelist_outcome)

# cohort       = spark.table(path_out_cohort)
spark.sql(f"""REFRESH TABLE {dbc}.{proj}_out_vacc_cohort""")
cohort       = spark.table(f'{dbc}.{proj}_out_vacc_cohort')

spark.sql(f"""REFRESH TABLE {path_cur_hes_apc_long}""")
hes_apc_long = spark.table(path_cur_hes_apc_long)

spark.sql(f"""REFRESH TABLE {path_cur_deaths_long}""")
deaths_long  = spark.table(path_cur_deaths_long)

# COMMAND ----------

# MAGIC %md # 2 Prepare

# COMMAND ----------

display(cohort)

# COMMAND ----------

print('--------------------------------------------------------------------------------------')
print('individual_censor_dates')
print('--------------------------------------------------------------------------------------')
# check
print(f'proj_child_vacc_end_date = {proj_child_vacc_end_date}')
# assert proj_child_vacc_end_date == '2023-02-28'
# note: applying maximum CENSOR_DATE_END (= 2022-12-31) for all individuals to provide AS with flexibility in R

individual_censor_dates = (
  cohort
  .select('PERSON_ID', f.col('baseline_date').alias('CENSOR_DATE_START'))
  .withColumn('CENSOR_DATE_END', f.to_date(f.lit(f'{proj_child_vacc_end_date}'))))

# check
count_var(individual_censor_dates, 'PERSON_ID'); print()
print(individual_censor_dates.limit(10).toPandas().to_string()); print()


print('--------------------------------------------------------------------------------------')
print('hes_apc')
print('--------------------------------------------------------------------------------------')
# check
tmpt = tab(hes_apc_long, 'DIAG_POSITION'); print()

# filter to primary diagnosis position
# reduce and rename columns
_hes_apc = hes_apc_long\
  .where(f.col('DIAG_POSITION') == 1)\
  .select(['PERSON_ID', 'EPISTART', 'CODE', 'DIAG_POSITION'])\
  .withColumnRenamed('EPISTART', 'DATE')

# check
count_var(_hes_apc, 'PERSON_ID'); print()
tmpt = tab(_hes_apc, 'DIAG_POSITION'); print()

# add individual censor dates
_hes_apc = merge(_hes_apc.drop('DIAG_POSITION'), individual_censor_dates, ['PERSON_ID'], validate='m:1', keep_results=['both'], indicator=0); print()

# check
count_var(_hes_apc, 'PERSON_ID'); print()

# filter to after CENSOR_DATE_START and on or before CENSOR_DATE_END
_hes_apc = _hes_apc\
  .where(\
    (f.col('DATE') > f.col('CENSOR_DATE_START'))\
    & (f.col('DATE') <= f.col('CENSOR_DATE_END'))\
  )

# check
count_var(_hes_apc, 'PERSON_ID'); print()


print('--------------------------------------------------------------------------------------')
print('deaths')
print('--------------------------------------------------------------------------------------')
# check
tmpt = tab(deaths_long, 'DIAG_POSITION'); print()

# filter to underlying diagnosis position
# reduce and rename columns
_deaths = deaths_long\
  .where(f.col('DIAG_POSITION') == 'UNDERLYING')\
  .select(['PERSON_ID', 'DATE', 'CODE', 'DIAG_POSITION'])

# check
count_var(_deaths, 'PERSON_ID'); print()
tmpt = tab(_deaths, 'DIAG_POSITION'); print()

# add individual censor dates
_deaths = _deaths\
  .drop('DIAG_POSITION')\
  .join(individual_censor_dates, on='PERSON_ID', how='inner')

# check
count_var(_deaths, 'PERSON_ID'); print()

# filter to after CENSOR_DATE_START and on or before CENSOR_DATE_END
_deaths = _deaths\
  .where(\
    (f.col('DATE') > f.col('CENSOR_DATE_START'))\
    & (f.col('DATE') <= f.col('CENSOR_DATE_END'))\
  )

# check
count_var(_deaths, 'PERSON_ID'); print()


print('--------------------------------------------------------------------------------------')
print('cache')
print('--------------------------------------------------------------------------------------')
_hes_apc.cache()
print(f'_hes_apc {_hes_apc.count():,}')
_deaths.cache()
print(f'_deaths  {_deaths.count():,}')

# COMMAND ----------

# check codelist
tmpt = tab(codelist, 'name' , 'terminology', var2_unstyled=1); print()

# COMMAND ----------

# MAGIC %md # 3 Create

# COMMAND ----------

# dictionary - dataset, codelist, and ordering in the event of tied records
_out_in = {
  'hes_apc': ['_hes_apc', 'codelist',  2]
  , 'deaths':  ['_deaths',  'codelist',  1]
}

# run codelist match and codelist match summary functions
_out, _out_1st, _out_1st_wide = codelist_match(_out_in, _name_prefix=f'out_')
_out_summ_name, _out_summ_name_code = codelist_match_summ(_out_in, _out)

# drop flags for AS
_out_1st_wide = _out_1st_wide.drop(*[var for var in _out_1st_wide.columns if re.match('^out_.*_flag$', var)])

# COMMAND ----------

# MAGIC %md # 4 Check

# COMMAND ----------

# MAGIC %md ## 4.0 Display

# COMMAND ----------

# check result
display(_out_1st_wide)

# COMMAND ----------

# MAGIC %md ## 4.1 Plots - First event - Over follow-up time (years) by data source (stacked)

# COMMAND ----------

# DBTITLE 1,Independent y-axes
# _tmp = _out_1st\
#   .withColumn('diff', f.datediff(f.col('DATE'), f.col('CENSOR_DATE_START'))/365.25)
# _tmpp = _tmp\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.4*rows_of_5), sharex=True) # , sharey=True , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['hes_apc', 'deaths']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
#   tmp2d1 = _tmpp[(_tmpp[f'diff'] > -30) & (_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'source'] == 'hes_apc'][f'diff'])
#   s2 = list(tmp2d1[tmp2d1[f'source'] == 'deaths'][f'diff'])
#   ax.hist([s1, s2], bins = list(np.linspace(0,3,100)), stacked=True, color=colors, label=names) # normed=True
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nFollow-up (years)\n')
#   ax.xaxis.set_tick_params(labelbottom=True)
#   if(i==0): ax.legend(loc='upper right')
    
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)
    
# plt.tight_layout();
# display(fig)

# COMMAND ----------

# DBTITLE 1,Shared y-axes
# _tmp = _out_1st\
#   .withColumn('diff', f.datediff(f.col('DATE'), f.col('CENSOR_DATE_START'))/365.25)
# _tmpp = _tmp\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.4*rows_of_5), sharex=True, sharey=True) #  , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['hes_apc', 'deaths']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
#   tmp2d1 = _tmpp[(_tmpp[f'diff'] > -30) & (_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'source'] == 'hes_apc'][f'diff'])
#   s2 = list(tmp2d1[tmp2d1[f'source'] == 'deaths'][f'diff'])
#   ax.hist([s1, s2], bins = list(np.linspace(0,3,100)), stacked=True, color=colors, label=names) # normed=True
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nFollow-up (years)\n')
#   ax.xaxis.set_tick_params(labelbottom=True)
#   if(i==0): ax.legend(loc='upper right')
    
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)
    
# plt.tight_layout();
# display(fig)

# COMMAND ----------

# MAGIC %md ## 4.2 Plots - First event - Over calendar time by data source (stacked)

# COMMAND ----------

# DBTITLE 1,Independent y-axes
# _tmpp = _out_1st\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.8*rows_of_5), sharex=True) # , sharey=True , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['hes_apc', 'deaths']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
  
#   tmp2d1 = _tmpp[(_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'source'] == 'hes_apc'][f'DATE'])
#   s2 = list(tmp2d1[tmp2d1[f'source'] == 'deaths'][f'DATE'])
#   ax.hist([s1, s2], bins=100, stacked=True, color=colors, label=names) # normed=True # bins = list(np.linspace(0,3,100))
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nDate\n')
#   if(i==0): ax.legend(loc='upper right')
  
#   # plt.draw()
#   # ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
#   ax.xaxis.set_tick_params(rotation=90) # labelbottom=True)
  
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)


# plt.tight_layout();
# display(fig)

# COMMAND ----------

# DBTITLE 1,Shared y-axes
# _tmpp = _out_1st\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.8*rows_of_5), sharex=True, sharey=True) # , sharey=True , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['hes_apc', 'deaths']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
  
#   tmp2d1 = _tmpp[(_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'source'] == 'hes_apc'][f'DATE'])
#   s2 = list(tmp2d1[tmp2d1[f'source'] == 'deaths'][f'DATE'])
#   ax.hist([s1, s2], bins=100, stacked=True, color=colors, label=names) # normed=True # bins = list(np.linspace(0,3,100))
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nDate\n')
#   if(i==0): ax.legend(loc='upper right')
  
#   # plt.draw()
#   # ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
#   ax.xaxis.set_tick_params(rotation=90) # labelbottom=True)
  
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)


# plt.tight_layout();
# display(fig)

# COMMAND ----------

# MAGIC %md ## 4.3 Plots - First event - Over age at event (years) by data source (stacked)

# COMMAND ----------

# DBTITLE 1,Independent y-axes
# # plot age instead of diff
# _tmp = (merge(_out_1st, cohort.select('PERSON_ID', 'DOB'), ['PERSON_ID'], validate='m:1', assert_results=['both', 'right_only'], keep_results=['both'])
#   .withColumn('diff', f.datediff(f.col('DATE'), f.col('DOB'))/365.25))
# _tmpp = _tmp\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.4*rows_of_5), sharex=True) # , sharey=True , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['hes_apc', 'deaths']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
#   tmp2d1 = _tmpp[(_tmpp[f'diff'] > -30) & (_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'source'] == 'hes_apc'][f'diff'])
#   s2 = list(tmp2d1[tmp2d1[f'source'] == 'deaths'][f'diff'])
#   ax.hist([s1, s2], bins = list(np.linspace(0,20,100)), stacked=True, color=colors, label=names) # normed=True
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nAge (years)\n')
#   ax.xaxis.set_tick_params(labelbottom=True)
#   if(i==0): ax.legend(loc='upper right')
    
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)

# plt.tight_layout();
# display(fig)

# COMMAND ----------

# DBTITLE 1,Shared y-axes
# # plot age instead of diff
# _tmp = (merge(_out_1st, cohort.select('PERSON_ID', 'DOB'), ['PERSON_ID'], validate='m:1', assert_results=['both', 'right_only'], keep_results=['both'])
#   .withColumn('diff', f.datediff(f.col('DATE'), f.col('DOB'))/365.25))
# _tmpp = _tmp\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.4*rows_of_5), sharex=True, sharey=True) # , sharey=True , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['hes_apc', 'deaths']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
#   tmp2d1 = _tmpp[(_tmpp[f'diff'] > -30) & (_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'source'] == 'hes_apc'][f'diff'])
#   s2 = list(tmp2d1[tmp2d1[f'source'] == 'deaths'][f'diff'])
#   ax.hist([s1, s2], bins = list(np.linspace(0,20,100)), stacked=True, color=colors, label=names) # normed=True
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nAge (years)\n')
#   ax.xaxis.set_tick_params(labelbottom=True)
#   if(i==0): ax.legend(loc='upper right')
    
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)

# plt.tight_layout();
# display(fig)

# COMMAND ----------

# MAGIC %md ## 4.4 Plots - First event - Over age at event (years) by sex (overlapping)

# COMMAND ----------

# DBTITLE 1,Independent y-axes 
# # plot age instead of diff
# _tmp = (merge(_out_1st, cohort.select('PERSON_ID', 'DOB', 'SEX'), ['PERSON_ID'], validate='m:1', assert_results=['both', 'right_only'], keep_results=['both'])
#   .withColumn('diff', f.datediff(f.col('DATE'), f.col('DOB'))/365.25))
# _tmpp = _tmp\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.4*rows_of_5), sharex=True) # , sharey=True , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['Male', 'Female']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
#   tmp2d1 = _tmpp[(_tmpp[f'diff'] > -30) & (_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'SEX'] == '1'][f'diff'])
#   s2 = list(tmp2d1[tmp2d1[f'SEX'] == '2'][f'diff'])
#   # ax.hist([s1, s2], bins = list(np.linspace(0,20,100)), stacked=True, color=colors, label=names) # normed=True 
#   ax.hist(s1, bins = list(np.linspace(0,20,100)), color=colors[0], label=names[0], alpha=0.5) # normed=True 
#   ax.hist(s2, bins = list(np.linspace(0,20,100)), color=colors[1], label=names[1], alpha=0.5) # normed=True 
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nAge (years)\n')
#   ax.xaxis.set_tick_params(labelbottom=True)
#   if(i==0): ax.legend(loc='upper right')
    
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)
    
# plt.tight_layout();
# display(fig)

# COMMAND ----------

# DBTITLE 1,Shared y-axes
# # plot age instead of diff
# _tmp = (merge(_out_1st, cohort.select('PERSON_ID', 'DOB', 'SEX'), ['PERSON_ID'], validate='m:1', assert_results=['both', 'right_only'], keep_results=['both'])
#   .withColumn('diff', f.datediff(f.col('DATE'), f.col('DOB'))/365.25))
# _tmpp = _tmp\
#   .toPandas()

# plt.rcParams.update({'font.size': 8})
# rows_of_5 = np.ceil(len(_tmpp['name'].drop_duplicates())/5).astype(int)
# fig, axes = plt.subplots(rows_of_5, 5, figsize=(13,2.4*rows_of_5), sharex=True, sharey=True) # , sharey=True , dpi=100) # 
 
# colors = sns.color_palette("tab10", 2)
# names = ['Male', 'Female']  
  
# vlist = list(_tmpp[['name']].drop_duplicates().sort_values('name')['name']) # ['AMI', 'BMI_obesity', 'CKD', 'COPD']  
# for i, (ax, v) in enumerate(zip(axes.flatten(), vlist)):
#   print(i, ax, v)
#   tmp2d1 = _tmpp[(_tmpp[f'diff'] > -30) & (_tmpp[f'name'] == v)]
#   s1 = list(tmp2d1[tmp2d1[f'SEX'] == '1'][f'diff'])
#   s2 = list(tmp2d1[tmp2d1[f'SEX'] == '2'][f'diff'])
#   # ax.hist([s1, s2], bins = list(np.linspace(0,20,100)), stacked=True, color=colors, label=names) # normed=True
#   ax.hist(s1, bins = list(np.linspace(0,20,100)), color=colors[0], label=names[0], alpha=0.5) # normed=True 
#   ax.hist(s2, bins = list(np.linspace(0,20,100)), color=colors[1], label=names[1], alpha=0.5) # normed=True 
#   ax.set_title(f'{v}')
#   ax.set(xlabel='\nAge (years)\n')
#   ax.xaxis.set_tick_params(labelbottom=True)
#   if(i==0): ax.legend(loc='upper right')
    
# axes[3,1].set_axis_off()
# axes[3,2].set_axis_off()
# axes[3,3].set_axis_off()
# axes[3,4].set_axis_off()
# for i in range(0,3):
#   for j in range(0, 5):
#     axes[i,j].xaxis.set_tick_params(labelbottom=True)
    
# plt.tight_layout();
# display(fig)

# COMMAND ----------

# MAGIC %md ## 4.5 Numerical summaries of plots

# COMMAND ----------

# check numerical summaries 
tmpf = (merge(_out_1st, cohort.select('PERSON_ID', 'DOB', 'SEX'), ['PERSON_ID'], validate='m:1', assert_results=['both', 'right_only'], keep_results=['both'])
        .withColumn('diff', f.datediff(f.col('DATE'), f.col('CENSOR_DATE_START'))/365.25)
        .withColumn('age', f.datediff(f.col('DATE'), f.col('DOB'))/365.25)
        .withColumn('name_source', f.concat_ws('_', 'name', 'source'))
        .withColumn('name_sex', f.concat_ws('_', 'name', 'SEX'))); print()
tmpt = tabstat(tmpf, 'diff', byvar='name_source'); print()
tmpt = tabstat(tmpf, 'DATE', byvar='name_source', date=1); print()
tmpt = tabstat(tmpf, 'age',  byvar='name_source'); print()
tmpt = tabstat(tmpf, 'age',  byvar='name_sex'); print()

# COMMAND ----------

# MAGIC %md ## 4.6 Codelist match summaries

# COMMAND ----------

# check codelist match summary by name and source
display(_out_summ_name)

# COMMAND ----------

# check codelist match summary by name, source, and code
display(_out_summ_name_code)

# COMMAND ----------

# suppress cols in tmp1 by creating a new dataframe tmpp2 - to be able to export
tmpp2 = _out_summ_name
cols = ['n_hes_apc', 'n_id_hes_apc', 'n_deaths' ,'n_id_deaths', 'n_all', 'n_id_all']
for i, var in enumerate(cols):
  tmpp2 = tmpp2.withColumn(var, f.col(var).cast(t.IntegerType()))
  typ = dict(tmpp2.dtypes)[var]
  print(i, var, typ)  
  assert str(typ) in('bigint')
  assert tmpp2.where(f.col(var)<0).count() == 0
  tmpp2 = (tmpp2
         .withColumn(var,
                     f.when(f.col(var) == 0, 0)
                     .when(f.col(var) < 10, 10)
                     .when(f.col(var) >= 10, 5*f.round(f.col(var)/5))
                    )
        )

# COMMAND ----------

display(tmpp2)

# COMMAND ----------

# check codelist match summary by name, source, and code
display(tmpp2)

# COMMAND ----------

export_counts_code = _out_summ_name_code
cols = ['n', 'n_id']
for i, var in enumerate(cols):
  export_counts_code = export_counts_code.withColumn(var, f.col(var).cast(t.IntegerType()))
  typ = dict(export_counts_code.dtypes)[var]
  print(i, var, typ)  
  assert str(typ) in('bigint')
  assert export_counts_code.where(f.col(var)<0).count() == 0
  export_counts_code = (export_counts_code
         .withColumn(var,
                     f.when(f.col(var) == 0, 0)
                     .when(f.col(var) < 10, 10)
                     .when(f.col(var) >= 10, 5*f.round(f.col(var)/5))
                    )
        )


# COMMAND ----------

# export_counts_code = export_counts_code.filter(export_counts_code.n != 0)
display(export_counts_code)

# COMMAND ----------

# MAGIC %md # 5 Save

# COMMAND ----------

# save name
outName = f'{proj}_out_vacc_outcomes'.lower()

# save
_out_1st_wide.write.mode('overwrite').saveAsTable(f'{dbc}.{outName}')
#spark.sql(f'ALTER TABLE {dbc}.{outName} OWNER TO {dbc}')

# COMMAND ----------

# save codelist match summary tables
list_tables = ['_out_summ_name', '_out_summ_name_code']
for i, table in enumerate(list_tables):
  print(i, table)
  outName = f'{proj}_out_vacc_codelist_match{table}'.lower()
  tmp1 = globals()[table]
  tmp1.write.mode('overwrite').saveAsTable(f'{dbc}.{outName}')
  spark.sql(f'ALTER TABLE {dbc}.{outName} OWNER TO {dbc}')
  print(f'  saved {dbc}.{outName}')
